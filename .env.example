# OpenAI API Configuration
# For OpenAI: use https://api.openai.com/v1
# For other providers (e.g., OpenRouter): use their base URL
OPENAI_BASE_URL=https://api.openai.com/v1

# Your API key from the service provider
OPENAI_API_KEY=sk-your-api-key-here

# Model to use (e.g., gpt-4, gpt-3.5-turbo, or provider-specific models)
OPENAI_MODEL=gpt-3.5-turbo

# ============================================
# Memory Service Configuration
# ============================================

# Enable/disable memory service
MEMORY_ENABLED=true

# OpenSearch Configuration
OPENSEARCH_NODE=http://localhost:9200
OPENSEARCH_USERNAME=admin
OPENSEARCH_PASSWORD=YourStrongPassword123!
OPENSEARCH_INDEX=chatbot_memories

# Embedding Configuration
# Provider: openai, cohere, or local
EMBEDDING_PROVIDER=openai
# For OpenAI: text-embedding-3-small (1536 dims) or text-embedding-3-large (3072 dims)
EMBEDDING_MODEL=text-embedding-3-small
# Must match the model's output dimensions
EMBEDDING_DIMENSIONS=1536

# Memory Behavior
# Similarity threshold for memory retrieval (0.0 - 1.0)
# Higher = more strict matching, Lower = more lenient
MEMORY_SIMILARITY_THRESHOLD=0.7
# Maximum number of memories to retrieve per query
MEMORY_RETRIEVAL_LIMIT=5
# Enable automatic fact extraction from conversations
MEMORY_EXTRACTION_ENABLED=true

# Database Configuration
# SQLite:
DATABASE_URL=file:./data/chatbot.db
# PostgreSQL:
# DATABASE_URL=postgresql://username:password@localhost:5432/chatbot_memory

# Performance Settings
# Cache TTL in seconds (how long to cache embeddings)
MEMORY_CACHE_TTL=3600
# Batch size for processing multiple memories
MEMORY_BATCH_SIZE=10
